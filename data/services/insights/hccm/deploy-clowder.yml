---
$schema: /app-sre/saas-file-2.yml

labels:
  service: hccm
  platform: insights

name: hccm-clowder
description: hccm app on the Insights Platform deployed with Clowder

app:
  $ref: /services/insights/hccm/app.yml

pipelinesProvider:
  $ref: /services/insights/pipelines/tekton.crc-pipelines.appsrep05ue1.yaml

deployResources:
  requests:
    cpu: 300m
    memory: 600Mi
  limits:
    cpu: 300m
    memory: 600Mi

slack:
  workspace:
    $ref: /dependencies/slack/redhat-internal.yml
  channel: cost-mgmt-bots

managedResourceTypes:
- ClowdApp
- ConfigMap
- ClowdJobInvocation
- Frontend

imagePatterns:
- quay.io/cloudservices
- quay.io/app-sre

authentication:
  image:
    path: insights/quay/cloudservices-push
    field: all
    version: 3

parameters:
  CLOWDER_ENABLED: true
  ACCOUNT_ENHANCED_METRICS: False

resourceTemplates:
- name: koku-cji
  # repo deploy file: https://github.com/project-koku/koku/blob/main/deploy/koku-cji.yaml
  # container image: quay.io/cloudservices/koku
  # container repo:  https://quay.io/repository/cloudservices/koku
  path: /deploy/koku-cji.yaml
  url: https://github.com/project-koku/koku
  targets:
  # Staging:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: 3dc9c29878a6fe45722c899fbdae730e7a203642
    parameters:
      CJI_INVOCATION: "01"

  # Production:
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 3dc9c29878a6fe45722c899fbdae730e7a203642
    parameters:
      CJI_INVOCATION: "01"

- name: koku
  # repo deploy file: https://github.com/project-koku/koku/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/koku
  # container repo:  https://quay.io/repository/cloudservices/koku
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/koku
  targets:

  # Ephemeral
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
    parameters:
      ENABLE_HCS_DEBUG: True
      ENABLE_S3_ARCHIVING: True
      AUTO_DATA_INGEST: True
      RETAIN_NUM_MONTHS: 4
      PARQUET_PROCESSING_BATCH_SIZE: "500000"
      TRINO_DATE_STEP: 31
      PRESTO_HOST: trino-coordinator
      TRINO_HOST: trino-coordinator
      # Deployment specific variables:
      # nginx
      NGINX_REPLICAS: 2
      # koku-api
      KOKU_REPLICAS: 1
      # listener
      LISTENER_REPLICAS: 2
      # masu
      MASU_REPLICAS: 1
      # scheduler
      SCHEDULER_REPLICAS: 1
      # sources-client
      SOURCES_CLIENT_REPLICAS: 1
      # sources-listener
      SOURCES_LISTENER_REPLICAS: 1
      # worker-celery
      WORKER_CELERY_REPLICAS: 1
      # worker-cost-model
      WORKER_COST_MODEL_REPLICAS: 1
      # worker-download
      WORKER_DOWNLOAD_REPLICAS: 2
      # worker-ocp
      WORKER_OCP_REPLICAS: 2
      # worker-priority
      WORKER_PRIORITY_REPLICAS: 2
      # worker-refresh
      WORKER_REFRESH_REPLICAS: 1
      # worker-summary
      WORKER_SUMMARY_REPLICAS: 2
      # worker-hcs
      WORKER_HCS_REPLICAS: 1
      # Change these settings when deploying migrations to Ephemeral
      # Migrations Image Tag
      # DBM_IMAGE_TAG: x
      # Migrations Invocation
      # DBM_INVOCATION: "00"
      # Migration directive is optional and should be in the form of:
      # <app>[:<migration>][,<app>[:<migration>]...]
      # Ex: "reporting:0200,api:0050"
      # Ex: "reporting:0200"
      # Ex: "reporting"
      # Ex: ""
      # _MIGRATION_DIRECTIVE: ""
      # Enhanced Org Admin
      ENHANCED_ORG_ADMIN: True
      UNLEASH_LOG_LEVEL: "ERROR"


  # Staging:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-koku-gh-build-main
    parameters:
      ############# MIGRATIONS #############
      # Change these settings when deploying migrations to Staging
      # Migrations Image Tag
      DBM_IMAGE_TAG: 13efbbb
      # Migrations Invocation
      DBM_INVOCATION: "00"
      # Migration directive is optional and should be in the form of:
      # <app>[:<migration>][,<app>[:<migration>]...]
      # Ex: "reporting:0200,api:0050"
      # Ex: "reporting:0200"
      # Ex: "reporting"
      # Ex: ""
      _MIGRATION_DIRECTIVE: ""
      ######################################
      APP_DOMAIN: apps.crcs02ue1.urby.p1.openshiftapps.com
      ROS_OCP_API: ros-ocp-backend-api.ros-stage.svc.cluster.local
      S3_BUCKET_NAME: hccm-stage-s3
      S3_ROS_BUCKET_NAME: hccm-ros-stage-s3
      KOKU_SENTRY_ENV: stage
      ENABLE_API_SENTRY: True
      ENABLE_CELERY_SENTRY: True
      DEMO_ACCOUNTS: '{"6193296":{"arn:aws:iam::589173575009:role/NisePopulatorAccessRole":{"source_type": "AWS", "report_prefix":"cur","report_name":"awscost"},"5d4eb34d-43c7-4b06-8257-1cb599b48d1e":{"source_type": "Azure", "report_prefix":"cur","report_name":"azurecost","container_name":"cur"}}}'
      ENABLE_PARQUET_PROCESSING: True
      ENABLE_S3_ARCHIVING: True
      ENABLE_TRINO_SOURCES: ''
      ENABLE_TRINO_SOURCE_TYPE: 'GCP'
      ENABLE_TRINO_ACCOUNTS: 'acct6193296'
      TRINO_DATE_STEP: 31
      AUTO_DATA_INGEST: True
      UPDATE_TIMEOUT: 14400
      RETAIN_NUM_MONTHS: 4
      VACUUM_DATA_DAY_OF_WEEK: 0
      REPORT_DOWNLOAD_SCHEDULE: "0 4,16 * * *"
      PARQUET_PROCESSING_BATCH_SIZE: "500000"
      PRESTO_HOST: trino-coordinator
      TRINO_HOST: trino-coordinator
      RBAC_CACHE_TIMEOUT: 1
      CACHE_TIMEOUT: 1
      # Deployment specific variables:
      # koku-api
      KOKU_REPLICAS: 3
      KOKU_CPU_REQUEST: 100m
      KOKU_CPU_LIMIT: 1
      KOKU_MEMORY_REQUEST: 768Mi
      KOKU_MEMORY_LIMIT: 1536Mi
      # listener
      LISTENER_REPLICAS: 3
      LISTENER_CPU_REQUEST: 200m
      LISTENER_CPU_LIMIT: 500m
      LISTENER_MEMORY_REQUEST: 512Mi
      LISTENER_MEMORY_LIMIT: 1Gi
      # masu
      MASU_REPLICAS: 1
      MASU_MEMORY_REQUEST: 512Mi
      MASU_MEMORY_LIMIT: 1Gi
      # scheduler
      SCHEDULER_REPLICAS: 1
      SCHEDULER_MEMORY_REQUEST: 256Mi
      SCHEDULER_MEMORY_LIMIT: 512Mi
      # sources-client
      SOURCES_CLIENT_REPLICAS: 3
      SOURCES_CLIENT_CPU_REQUEST: 50m
      SOURCES_CLIENT_CPU_LIMIT: 250m
      SOURCES_CLIENT_MEMORY_REQUEST: 256Mi
      SOURCES_CLIENT_MEMORY_LIMIT: 512Mi
      # sources-listener
      SOURCES_LISTENER_REPLICAS: 1
      SOURCES_LISTENER_CPU_REQUEST: 50m
      SOURCES_LISTENER_CPU_LIMIT: 250m
      SOURCES_LISTENER_MEMORY_REQUEST: 256Mi
      SOURCES_LISTENER_MEMORY_LIMIT: 512Mi
      # workers global
      WORKER_PROC_ALIVE_TIMEOUT: 8
      # worker-celery
      WORKER_CELERY_REPLICAS: 3
      WORKER_CELERY_CPU_REQUEST: 50m
      WORKER_CELERY_CPU_LIMIT: 250m
      WORKER_CELERY_MEMORY_REQUEST: 512Mi
      WORKER_CELERY_MEMORY_LIMIT: 1Gi
      # worker-cost-model
      WORKER_COST_MODEL_REPLICAS: 3
      WORKER_COST_MODEL_CPU_REQUEST: 50m
      WORKER_COST_MODEL_CPU_LIMIT: 200m
      WORKER_COST_MODEL_MEMORY_REQUEST: 400Mi
      WORKER_COST_MODEL_MEMORY_LIMIT: 600Mi
      # worker-download
      WORKER_DOWNLOAD_REPLICAS: 3
      WORKER_DOWNLOAD_CPU_REQUEST: 500m
      WORKER_DOWNLOAD_CPU_LIMIT: 1
      WORKER_DOWNLOAD_MEMORY_REQUEST: 5Gi
      WORKER_DOWNLOAD_MEMORY_LIMIT: 8Gi
      # worker-ocp
      WORKER_OCP_REPLICAS: 3
      WORKER_OCP_CPU_REQUEST: 75m
      WORKER_OCP_CPU_LIMIT: 200m
      WORKER_OCP_MEMORY_REQUEST: 600Mi
      WORKER_OCP_MEMORY_LIMIT: 600Mi
      # worker-priority
      WORKER_PRIORITY_REPLICAS: 3
      WORKER_PRIORITY_CPU_REQUEST: 75m
      WORKER_PRIORITY_CPU_LIMIT: 500m
      WORKER_PRIORITY_MEMORY_REQUEST: 1Gi
      WORKER_PRIORITY_MEMORY_LIMIT: 2Gi
      # worker-refresh
      WORKER_REFRESH_REPLICAS: 3
      WORKER_REFRESH_CPU_REQUEST: 50m
      WORKER_REFRESH_CPU_LIMIT: 200m
      WORKER_REFRESH_MEMORY_REQUEST: 420Mi
      WORKER_REFRESH_MEMORY_LIMIT: 600Mi
      # worker-summary
      WORKER_SUMMARY_REPLICAS: 3
      WORKER_SUMMARY_CPU_REQUEST: 75m
      WORKER_SUMMARY_CPU_LIMIT: 200m
      WORKER_SUMMARY_MEMORY_REQUEST: 650Mi
      WORKER_SUMMARY_MEMORY_LIMIT: 800Mi
      # worker-hcs
      WORKER_HCS_REPLICAS: 3
      WORKER_HCS_CPU_REQUEST: 75m
      WORKER_HCS_CPU_LIMIT: 200m
      WORKER_HCS_MEMORY_REQUEST: 425Mi
      WORKER_HCS_MEMORY_LIMIT: 600Mi


  # Production:
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: ccd4f877f9ca6f3bae18edee26dc5f2312fdaaa7
    parameters:
      ############# MIGRATIONS #############
      # Change these settings when deploying migrations to Production
      # Migrations Image Tag
      DBM_IMAGE_TAG: 30de988
      # Migrations Invocation
      DBM_INVOCATION: "00"
      # Migration directive is optional and should be in the form of:
      # <app>[:<migration>][,<app>[:<migration>]...]
      # Ex: "reporting:0200,api:0050"
      # Ex: "reporting:0200"
      # Ex: "reporting"
      # Ex: ""
      _MIGRATION_DIRECTIVE: ""
      ######################################
      APP_DOMAIN: apps.crcp01ue1.o9m8.p1.openshiftapps.com
      S3_BUCKET_NAME: hccm-prod-s3
      S3_ROS_BUCKET_NAME: hccm-ros-prod-s3
      KOKU_SENTRY_ENV: prod
      ENABLE_API_SENTRY: True
      ENABLE_CELERY_SENTRY: True
      DEMO_ACCOUNTS: '{"6193296":{"arn:aws:iam::589173575009:role/NisePopulatorAccessRole":{"source_type": "AWS", "report_prefix":"cur","report_name":"awscost"},"5d4eb34d-43c7-4b06-8257-1cb599b48d1e":{"source_type": "Azure", "report_prefix":"cur","report_name":"azurecost","container_name":"cur"}}}'
      ENABLE_PARQUET_PROCESSING: True
      ENABLE_S3_ARCHIVING: True
      ENABLE_TRINO_SOURCES: 'f71993c9-db47-4dcf-b375-c32d84502b13,118445f0-7304-4311-aa22-ed86b484f48d,79419ac3-cf38-450c-84cf-7d2accc2c293,889668d0-8bdc-4e96-84fe-4311b3514efb,b139babe-9f1a-4519-ae49-bfd4e06807a2,cbf2420e-ab4b-4ab3-b27c-d5a05d578262,d24bd391-fc65-4275-a7bb-174c91e1c9fe,f1eb8998-4984-4ee5-9bfb-f0370cb690a4,cc11e600-9888-4614-be92-634b132c0f44,a84c1928-4891-4ff0-b458-f4fd27a7218a,a6568967-155a-428f-a20c-3c5d46f45ad8,bfad1e15-91eb-478f-a600-ffb3b0ee1042'
      ENABLE_TRINO_SOURCE_TYPE: 'GCP'
      ENABLE_TRINO_ACCOUNTS: 'acct7049367'
      QE_SCHEMA: 'acct6089719'
      TRINO_DATE_STEP: 3  # 5
      AUTO_DATA_INGEST: True
      RETAIN_NUM_MONTHS: 5
      # INITIAL_INGEST_OVERRIDE: 'True'
      # INITIAL_INGEST_NUM_MONTHS: 1
      SCHEDULE_CHECK_INTERVAL: 720
      SOURCE_STATUS_FREQUENCY_MINUTES: 60
      UPDATE_TIMEOUT: 14400
      VACUUM_DATA_DAY_OF_WEEK: 0
      REPORT_DOWNLOAD_SCHEDULE: "0 6,18 * * *"
      PRESTO_HOST: trino-coordinator
      TRINO_HOST: trino-coordinator
      GUNICORN_THREADS: False
      GUNICORN_WORKERS: 2
      # Deployment specific variables:
      # koku-api
      KOKU_REPLICAS: 10
      KOKU_CPU_REQUEST: 250m
      KOKU_CPU_LIMIT: 1
      KOKU_MEMORY_REQUEST: 2Gi
      KOKU_MEMORY_LIMIT: 4Gi
      # listener
      LISTENER_REPLICAS: 3
      LISTENER_CPU_REQUEST: 200m
      LISTENER_CPU_LIMIT: 1
      LISTENER_MEMORY_REQUEST: 1Gi
      LISTENER_MEMORY_LIMIT: 2Gi
      # masu
      MASU_REPLICAS: 1
      MASU_MEMORY_REQUEST: 512Mi
      MASU_MEMORY_LIMIT: 1Gi
      # scheduler
      SCHEDULER_REPLICAS: 1  # 1
      SCHEDULER_MEMORY_REQUEST: 256Mi
      SCHEDULER_MEMORY_LIMIT: 512Mi
      # sources-client
      SOURCES_CLIENT_REPLICAS: 3
      SOURCES_CLIENT_CPU_REQUEST: 250m
      SOURCES_CLIENT_CPU_LIMIT: 500m
      SOURCES_CLIENT_MEMORY_REQUEST: 256Mi
      SOURCES_CLIENT_MEMORY_LIMIT: 1Gi
      # sources-listener
      SOURCES_LISTENER_REPLICAS: 1
      SOURCES_LISTENER_CPU_REQUEST: 250m
      SOURCES_LISTENER_CPU_LIMIT: 500m
      SOURCES_LISTENER_MEMORY_REQUEST: 256Mi
      SOURCES_LISTENER_MEMORY_LIMIT: 1Gi
      # workers global
      WORKER_PROC_ALIVE_TIMEOUT: 9
      # worker-celery
      WORKER_CELERY_REPLICAS: 3
      WORKER_CELERY_CPU_REQUEST: 200m
      WORKER_CELERY_CPU_LIMIT: 1
      WORKER_CELERY_MEMORY_REQUEST: 1Gi
      WORKER_CELERY_MEMORY_LIMIT: 2Gi
      # worker-cost-model
      WORKER_COST_MODEL_REPLICAS: 3
      WORKER_COST_MODEL_CPU_REQUEST: 100m
      WORKER_COST_MODEL_CPU_LIMIT: 300m
      WORKER_COST_MODEL_MEMORY_REQUEST: 512Mi
      WORKER_COST_MODEL_MEMORY_LIMIT: 1Gi
      # worker-download
      WORKER_DOWNLOAD_REPLICAS: 10  # 6
      WORKER_DOWNLOAD_CPU_REQUEST: 700m
      WORKER_DOWNLOAD_CPU_LIMIT: 1500m
      WORKER_DOWNLOAD_MEMORY_REQUEST: 5Gi
      WORKER_DOWNLOAD_MEMORY_LIMIT: 8Gi
      # worker-ocp
      WORKER_OCP_REPLICAS: 7  # 7
      WORKER_OCP_CPU_REQUEST: 300m
      WORKER_OCP_CPU_LIMIT: 500m
      WORKER_OCP_MEMORY_REQUEST: 1Gi
      WORKER_OCP_MEMORY_LIMIT: 2Gi
      # worker-priority
      WORKER_PRIORITY_REPLICAS: 3  # 3
      WORKER_PRIORITY_CPU_REQUEST: 500m
      WORKER_PRIORITY_CPU_LIMIT: 1
      WORKER_PRIORITY_MEMORY_REQUEST: 3Gi
      WORKER_PRIORITY_MEMORY_LIMIT: 5Gi
      # worker-refresh
      WORKER_REFRESH_REPLICAS: 3  # 3
      WORKER_REFRESH_CPU_REQUEST: 100m
      WORKER_REFRESH_CPU_LIMIT: 200m
      WORKER_REFRESH_MEMORY_REQUEST: 300Mi
      WORKER_REFRESH_MEMORY_LIMIT: 600Mi
      # worker-summary
      WORKER_SUMMARY_REPLICAS: 10  # 6
      WORKER_SUMMARY_CPU_REQUEST: 100m
      WORKER_SUMMARY_CPU_LIMIT: 200m
      WORKER_SUMMARY_MEMORY_REQUEST: 512Mi
      WORKER_SUMMARY_MEMORY_LIMIT: 2Gi
      # worker-hcs
      WORKER_HCS_REPLICAS: 3
      WORKER_HCS_CPU_REQUEST: 100m
      WORKER_HCS_CPU_LIMIT: 200m
      WORKER_HCS_MEMORY_REQUEST: 500Mi
      WORKER_HCS_MEMORY_LIMIT: 1Gi


- name: hive-metastore
  # repo deploy file: https://github.com/RedHatInsights/ubi-hive/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/ubi-hive
  # container repo:  https://quay.io/repository/cloudservices/ubi-hive
  path: /deploy/clowdapp.yaml
  url: https://github.com/RedHatInsights/ubi-hive
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
    parameters:
      IMAGE_TAG: 3.1.3-metastore-015
      S3_BUCKET_NAME: hccm-eph-s3
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: 691afe7a37e86f7365705552f6977ec55e5e00b3
    parameters:
      IMAGE_TAG: 3.1.3-metastore-015
      S3_BUCKET_NAME: hccm-stage-s3
      CPU_REQUEST: 200m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 6Gi
      MEMORY_LIMIT: 16Gi
      MAX_HEAP_SIZE: 14G
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: ab1350614a39ae246c77fedd1bc97c56da3e4347
    parameters:
      IMAGE_TAG: 3.1.3-metastore-015
      MIN_REPLICAS: 1
      S3_BUCKET_NAME: hccm-prod-s3
      CPU_REQUEST: 200m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 18Gi
      MEMORY_LIMIT: 20Gi
      MAX_HEAP_SIZE: 18G

- name: presto
  # repo deploy file: https://github.com/RedHatInsights/ubi-trino/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/ubi-trino
  # container repo:  https://quay.io/repository/cloudservices/ubi-trino
  path: /deploy/clowdapp.yaml
  url: https://github.com/RedHatInsights/ubi-trino
  targets:
  # Ephemeral
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
    parameters:
      IMAGE_TAG: 411-002
      S3_BUCKET_NAME: hccm-eph-s3
      S3_SSE_ENABLED: 'False'
      S3_SELECT_PUSHDOWN_ENABLED: 'False'
      WORKER_REPLICAS: 2
      COORDINATOR_CPU_REQUEST: 200m
      COORDINATOR_CPU_LIMIT: 1
      COORDINATOR_MEMORY_REQUEST: 4Gi
      COORDINATOR_MEMORY_LIMIT: 8Gi
      WORKER_CPU_REQUEST: 200m
      WORKER_CPU_LIMIT: 1
      WORKER_MEMORY_REQUEST: 4Gi
      WORKER_MEMORY_LIMIT: 8Gi
      MAX_HEAP_SIZE: 6G
      LIVENESS_PROBE_PERIOD: 120
      LIVENESS_PROBE_TIMEOUT: 120
  # Staging
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: 0d7bda946ac6a0f964cd2a5ed4ed9f5e2439ffab
    parameters:
      CONFIGMAP_HASH: '000002' # when a `ref` update only contains changes to ConfigMaps, randomize this value to cause trino to redeploy
      IMAGE_TAG: 411-002
      S3_BUCKET_NAME: hccm-stage-s3
      MACHINE_POOL_OPTION: memory-optimized
      COORDINATOR_REPLICAS: 1
      WORKER_REPLICAS: 3
      COORDINATOR_CPU_REQUEST: 600m
      COORDINATOR_CPU_LIMIT: 2
      COORDINATOR_MEMORY_REQUEST: 12Gi
      COORDINATOR_MEMORY_LIMIT: 36Gi
      WORKER_CPU_REQUEST: 300m
      WORKER_CPU_LIMIT: 2
      WORKER_MEMORY_REQUEST: 6Gi
      WORKER_MEMORY_LIMIT: 10Gi
      QUERY_MAX_MEMORY_PER_NODE: 6.5GB # (jvm max - heap headroom)
      QUERY_MAX_MEMORY: 19.5GB # (max per node * worker count)
      QUERY_MAX_TOTAL_MEMORY: 39GB # (max-memory * 2)
      MEMORY_HEAP_HEADROOM_PER_NODE: 1GB
      MAX_HEAP_SIZE: 7680M
      LIVENESS_PROBE_PERIOD: 120
      LIVENESS_PROBE_TIMEOUT: 120
  # Production
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 9f03f48c1fb15f80d527b175a78379d7b5cdf39f
    parameters:
      CONFIGMAP_HASH: 'gffsf6' # when a `ref` update only contains changes to ConfigMaps, randomize this value to cause trino to redeploy
      IMAGE_TAG: 405-002
      S3_BUCKET_NAME: hccm-prod-s3
      MACHINE_POOL_OPTION: memory-optimized
      COORDINATOR_REPLICAS: 1 # 1
      WORKER_REPLICAS: 4 # 4
      COORDINATOR_CPU_REQUEST: 4
      COORDINATOR_CPU_LIMIT: 7800m
      COORDINATOR_MEMORY_REQUEST: 54Gi
      COORDINATOR_MEMORY_LIMIT: 56Gi
      WORKER_CPU_REQUEST: 4
      WORKER_CPU_LIMIT: 7800m
      WORKER_MEMORY_REQUEST: 54Gi
      WORKER_MEMORY_LIMIT: 56Gi
      QUERY_MAX_MEMORY_PER_NODE: 25GB # (jvm max - heap headroom)
      QUERY_MAX_MEMORY: 100GB # (max per node * worker count)
      QUERY_MAX_TOTAL_MEMORY: 200GB # (max-memory * 2)
      MEMORY_HEAP_HEADROOM_PER_NODE: 25GB
      MAX_HEAP_SIZE: 51200M # 51200 == 50 GiB
      LIVENESS_PROBE_PERIOD: 120
      LIVENESS_PROBE_TIMEOUT: 120

- name: cost-report-emailer-config
  path: /saas-templates/configmap.yml
  url: https://gitlab.cee.redhat.com/cost-management/cost-report-emailer-config
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main

- name: koku-report-emailer
  # repo deploy file: https://github.com/project-koku/koku-report-emailer/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/koku-report-emailer
  # container repo:  https://quay.io/repository/cloudservices/koku-report-emailer
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/koku-report-emailer
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true # tells app-sre to not actually run the deploy job for this target
    ref: internal # altered by bonfire
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-koku-report-emailer-gh-build-main
    parameters:
      EMAIL_SCHEDULE: '0 13 * * 1,3,5'

- name: koku-daily
  # repo deploy file: https://github.com/project-koku/koku-daily/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/koku-daily
  # container repo:  https://quay.io/repository/cloudservices/koku-daily
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/koku-daily
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-koku-daily-gh-build-main
    parameters:
      PROMETHEUS_PUSH_GATEWAY: ${PROMETHEUS_PUSHGATEWAY}
      REPLICAS: 1
      APP_URL_PREFIX: /api/cost-management/v1/koku-daily/
      CPU_REQUEST: 125m
      CPU_LIMIT: 250m
      MEMORY_REQUEST: 250Mi
      MEMORY_LIMIT: 500Mi
      EMAIL_GROUPS: {"engineering": "cost-mgmt-metrics-eng@redhat.com", "marketing": "cost-mgmt-metrics-mkt@redhat.com"}
      S3_BUCKET_NAME: hccm-stage-s3
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: ff893095dfb2ce152d3929cfee217e1f4eda8341
    parameters:
      PROMETHEUS_PUSH_GATEWAY: ${PROMETHEUS_PUSHGATEWAY}
      REPLICAS: 1
      APP_URL_PREFIX: /api/cost-management/v1/koku-daily/
      CPU_REQUEST: 100m
      CPU_LIMIT: 250m
      MEMORY_REQUEST: 500Mi
      MEMORY_LIMIT: 1Gi
      EMAIL_GROUPS: {"engineering": "cost-mgmt-metrics-eng@redhat.com", "marketing": "cost-mgmt-metrics-mkt@redhat.com"}
      EMAIL_SCHEDULE: '0 17 * * *'
      S3_BUCKET_NAME: hccm-prod-s3
      S3_SCHEDULE: "0 19 * * *"
      WEEKLY_REPORT_SCHEDULED_DAY: "3"

- name: nise-populator
  # repo deploy file: https://github.com/project-koku/nise-populator/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/nise-populator
  # container repo:  https://quay.io/repository/cloudservices/nise-populator
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/nise-populator
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-nise-populator-gh-build-main
    parameters:
      CPU_REQUEST: 250m
      CPU_LIMIT: 500m
      MEMORY_REQUEST: 1Gi
      MEMORY_LIMIT: 2Gi
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 66d67ed148f49cf775a9bd681bb0ad865943018d
    parameters:
      CPU_REQUEST: 250m
      CPU_LIMIT: 500m
      POPULATE_SCHEDULE: "0 11 * * *"

- name: parquet-compactor
  # repo deploy file: https://github.com/project-koku/parquet-compactor/blob/main/deploy/clowdapp.yaml
  # container image: quay.io/cloudservices/parquet-compactor
  # container repo:  https://quay.io/repository/cloudservices/parquet-compactor
  path: /deploy/clowdapp.yaml
  url: https://github.com/project-koku/parquet-compactor
  targets:
  - namespace:
      $ref: /services/insights/hccm/namespaces/stage-hccm-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-ext/ci-ext.yml
      name: project-koku-parquet-compactor-gh-build-main
    parameters:
      S3_BUCKET_NAME: hccm-stage-s3
      POPULATE_SCHEDULE: "0 13 * * *"
      MEMORY_REQUEST: 8Gi
      MEMORY_LIMIT: 14Gi
  - namespace:
      $ref: /services/insights/hccm/namespaces/hccm-prod.yml
    ref: 25785002f4fe52d550522bfff5fb0b8216ed8c65
    parameters:
      S3_BUCKET_NAME: hccm-prod-s3
      POPULATE_SCHEDULE: "0 14 * * 1,4"
      MEMORY_REQUEST: 16Gi
      MEMORY_LIMIT: 20Gi
      CPU_LIMIT: 2

- name: hccm-frontend
  # repo deploy file: https://github.com/project-koku/koku-ui/blob/main/deploy/frontend.yaml
  # container image: quay.io/cloudservices/....... TBD
  # container repo:  https://quay.io/repository/cloudservices/....... TBD
  path: /deploy/frontend.yaml
  url: https://github.com/project-koku/koku-ui
  targets:
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/ephemeral-base.yml
    disable: true  # do not create an app-sre deploy job for ephemeral namespace
    ref: internal  # populated by bonfire
  - namespace:
      $ref: /services/insights/ephemeral/namespaces/consoledot-frontend-stage.yml
    ref: b775fda3b1f1f97c9f94f06cd546ecad1e973edc
    parameters:
      ENV_NAME: "env-stage"

- name: cost-management-dashboards
  # dashboards directory: https://github.com/project-koku/koku/tree/main/dashboards
  url: https://github.com/project-koku/koku
  path: /dashboards
  provider: directory
  targets:
    - namespace:
        $ref: /services/observability/namespaces/app-sre-observability-stage-int.yml
      ref: main

    - namespace:
        $ref: /services/observability/namespaces/app-sre-observability-production-int.yml
      ref: a025da861ebf646c2253f4fcaf10f3d5214d5c16
