---
$schema: /app-sre/saas-file-2.yml

labels:
  service: kas-fleet-manager

name: saas-kas-fleet-manager
description: 'SaaS tracking file for Kafka Service Fleet Manager'

app:
  $ref: /services/managed-services/app.yml

pipelinesProvider:
  $ref: /services/managed-services/pipelines/tekton.kas-fleet-manager-pipelines.appsrep05ue1.yaml

deployResources:
  requests:
    cpu: 300m
    memory: 600Mi
  limits:
    cpu: 300m
    memory: 600Mi

slack:
  workspace:
    $ref: /dependencies/slack/coreos.yml
  channel: mk-kas-fleet-manager

managedResourceTypes:
- Deployment
- Service
- ConfigMap

imagePatterns:
- quay.io/rhoas/kas-fleet-manager
- quay.io/centos/centos
- quay.io/rhoas/envoyproxy
- quay.io/observatorium/token-refresher
- quay.io/rhoas/mk-token-refresher

authentication:
  image:
    path: managed-services/quay-org-accounts/rhoas/robots/rhoas-pull
    field: all

resourceTemplates:
- name: observatorium-token-refresher
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/observatorium-token-refresher.yml
  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: main
    parameters:
      ISSUER_URL: ${SSO_BASE_URL}
      OBSERVATORIUM_URL: https://observatorium-mst.api.stage.openshift.com/api/metrics/v1/managedkafka
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE: quay.io/rhoas/mk-token-refresher
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE_TAG: 0b54d2e
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # Please note the following before updating this 'ref' property:
    # - The commit sha specified here should always be the same commit sha specified for the kas-fleet-manager ref in production.
    #   e.g. If the kas-fleet-manager version was updated in production, the value of this ref property must also be updated to match the new commit hash.
    # - Commits can be found here: https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/main
    # If in doubt, please check with the MK Control Plane team.
    # We are exploring how to automate this in the future.
    ref: 5ea97bf63bb65905c1d4f3bfe9d82c1176679183
    parameters:
      ISSUER_URL: ${SSO_BASE_URL}
      OBSERVATORIUM_URL: https://observatorium-mst.api.openshift.com/api/metrics/v1/managedkafka
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE: quay.io/rhoas/mk-token-refresher
      OBSERVATORIUM_TOKEN_REFRESHER_IMAGE_TAG: 0b54d2e
- name: kas-fleet-manager
  url: https://gitlab.cee.redhat.com/service/kas-fleet-manager
  path: /templates/service-template.yml
  parameters:
    # Global parameter - Affects Production and Stage
    IMAGE_REGISTRY: quay.io
    # Global parameter - Affects Production and Stage
    IMAGE_REPOSITORY: rhoas/kas-fleet-manager
    # Global parameter - Affects Production and Stage
    # SSO_BASE_URL is defined at the environment parameters level
    JWKS_URL: ${SSO_BASE_URL}/protocol/openid-connect/certs
    # Global parameter - Affects Production and Stage
    CLUSTER_OPENSHIFT_VERSION: ""
    # Global parameter - Affects Production and Stage
    CLUSTER_COMPUTE_MACHINE_TYPE: m5.2xlarge
    # Global parameter - Affects Production and Stage
    # Global parameter - Affects Production and Stage
    # Change this to false if you want the users to be able to use the service without accepting any terms
    ENABLE_TERMS_ACCEPTANCE: true
    # Global parameter - Affects Production and Stage
    # Change this to false if you want to disable the deny list feature feature
    ENABLE_DENY_LIST: true
    # Global parameter - Affects Production and Stage
    # Change this to false to disable sentry
    ENABLE_SENTRY: true
    # Global parameter - Affects Production and Stage
    # Enable the external Kafka certificate for all Kafka clusters
    ENABLE_KAFKA_EXTERNAL_CERTIFICATE: true
    # Global parameter - Affects Production and Stage
    # Enable the dedicate Ingress on the data plane clusters which all Kafka Clusters will use
    ENABLE_DEDICATED_INGRESS: true
    # Global parameter - Affects Production and Stage
    #The public HTTP host URL of the service
    SERVICE_PUBLIC_HOST_URL: ${OCM_BASE_URL}
    # Global parameter - Affects Production and Stage
    # A URL to repository containing external Kafka Observability configuration info for Obs. Operator to consume
    OBSERVABILITY_CONFIG_REPO: https://api.github.com/repos/bf2fc6cc711aee1a0c2a/observability-resources-mk/contents
    # Global parameter - Affects Production and Stage
    # Which channel (directory) within the config repo the Observability Operator should consume from
    OBSERVABILITY_CONFIG_CHANNEL: resources
    # Global parameters - Affects Production and Stage
    # Capacity settings for the base Kafka type
    KAFKA_CAPACITY_INGRESS_THROUGHPUT: "30Mi"
    KAFKA_CAPACITY_TOTAL_MAX_CONNECTIONS: "3000"
    KAFKA_CAPACITY_MAX_DATA_RETENTION_SIZE: "1000Gi"
    KAFKA_CAPACITY_MAX_DATA_RETENTION_PERIOD: "P14D"
    KAFKA_CAPACITY_MAX_CONNECTION_ATTEMPTS_PER_SEC: "100"

  targets:
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-stage.yml
    ref: main
    upstream:
      instance:
        $ref: /dependencies/ci-int/ci-int.yml
      name: service-kas-fleet-manager-gl-build-main
    parameters:
      DB_SSLMODE: verify-full
      ENVIRONMENT: stage
      REPLICAS: 6
      SENTRY_URL: sentry.stage.devshift.net
      SENTRY_PROJECT: 21
      MAS_SSO_BASE_URL: https://identity.api.stage.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      OCM_URL: https://api.openshift.com
      # The browser url for the Stage Streams for Apache Kafka console
      BROWSER_URL: ${CONSOLE_BASE_URL}/application-services/streams/kafkas/
      # Log level
      GLOG_V: 10
      # Image to be used by Envoy sidecar container
      ENVOY_IMAGE: quay.io/rhoas/envoyproxy:v1.20.2
      # AMS
      AMS_URL: ${OCM_BASE_URL}
      # Use the ams based quota management service
      QUOTA_TYPE: ams
      # Dex identity service url
      DEX_URL: http://dex-dex.apps.pbraun-observatorium.observability.rhmw.io
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.pbraun-observatorium.observability.rhmw.io
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: test
      # The value of this auth type ( "dex" or "redhat" ) will determine the auth type ( Dex or Red Hat SSO) implemented for the observability stack
      OBSERVATORIUM_AUTH_TYPE: redhat
      # Token Refresher URL
      OBSERVATORIUM_TOKEN_REFRESHER_URL: http://token-refresher.managed-services-stage.svc.cluster.local
      # Release tag within Config Repo to use for pulling index information
      OBSERVABILITY_CONFIG_TAG: v1.31.0
      # Observatorium Red Hat SSO tenant for observability stack
      OBSERVATORIUM_RHSSO_TENANT: managedkafka
      # Red Hat SSO Observability gateway
      OBSERVATORIUM_RHSSO_GATEWAY: https://observatorium-mst.api.stage.openshift.com
      # Red Hat SSO Observability realm
      OBSERVATORIUM_RHSSO_REALM: redhat-external
      # Red Hat SSO Observability auth server url
      OBSERVATORIUM_RHSSO_AUTH_SERVER_URL: https://sso.redhat.com/auth
      # Maximum number of partitions per cluster
      KAFKA_CAPACITY_MAX_PARTITIONS: "1000"
      # Changing this to true will delete all kafkas after their lifespan expired. The default is 48 hours.
      ENABLE_KAFKA_LIFE_SPAN: true
      # This value is the lifespan a kafka will have with the lifespan flag enabled. In hours.
      KAFKA_LIFE_SPAN: 2
      MAS_SSO_ENABLE_AUTH: true
      # Max allowed service accounts created by an organization
      MAX_ALLOWED_SERVICE_ACCOUNTS: 50
      # Max limit for the fetching the clients from mas-sso
      MAX_LIMIT_FOR_SSO_GET_CLIENTS: 100
      # Set domain name for Kafka instances
      KAFKA_DOMAIN_NAME: "bf2.kafka-stage.rhcloud.com"
      STRIMZI_OPERATOR_ADDON_ID: managed-kafka-qe
      KAS_FLEETSHARD_ADDON_ID: kas-fleetshard-operator-qe
      # The Cluster Logging Operator ID. An empty string indicates that the operator should not be installed.
      CLUSTER_LOGGING_OPERATOR_ADDON_ID: "cluster-logging-operator"
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # A list of users with read-only permissions for data plane clusters
      READ_ONLY_USERS:
        - "cgorman"   # Managed ACS developer
        - "ebenshet"  # Managed ACS developer
        - "jrodrig"   # Managed ACS developer
        - "sbaumer"   # Managed ACS developer
        - "schaudhr"  # Managed ACS developer
        - "shesselm"  # Managed ACS developer
        - "vwilson"   # Managed ACS developer
     # A list of kafka-sre users with cluster-admin permissions for data plane clusters
      KAFKA_SRE_USERS:
        - "agullon"
        - "davmarti"
        - "rlawton"
        - "robrien"
        - "rshelly"
        - "stobin"
        - "tdavidso"
        - "tdalton"
        - "kchernou"
        - "dffrench"
        - "jbriones"
        - "mziccard"
        - "akoserwa"
        - "ppaszki"
        - "pbraun"
        - "msoriano"
        - "mchitimb"
        - "npecka"
        - "ppatiern"
        - "shawkins"
        - "kwall"
        - "gryan"
        - "fvila"
        - "xiwu"
        - "lclarkeh"
        - "sbarker"
        - "rareddy"
        - "medgar"
        - "tcooper"
        - "mfreer"
        - "crarobin"
        - "pcremin"
        - "deepshar"
        - "hlipsig"
        - "raananda"
        - "sclarkso"
        - "jsarnovs"
        - "vbommana"
        - "jcueto"
        - "swoodman"
        - "srbiswas"
        - "vbusch"
        - "lukchen"
        - "kstanley"
        - "ebernard"
        - "aabdelre"
        - "ihutchin"

      # parameters for SUPPORTED_INSTANCE_TYPES
      SUPPORTED_INSTANCE_TYPES:
      - id: developer
        display_name: "Trial"
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "1Mi"
            egressThroughputPerSec: "1Mi"
            totalMaxConnections: 100
            maxDataRetentionSize: "10Gi"
            maxPartitions: 100
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 50
            maxMessageSize: "1Mi"
            minInSyncReplicas: 1
            replicationFactor: 1
            quotaConsumed: 1
            quotaType: "RHOSAKTrial"
            capacityConsumed: 1
            supportedAZModes:
            - single
            lifespanSeconds: 7200
            maturityStatus: stable
      - id: standard
        display_name: "Standard"
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "50Mi"
            egressThroughputPerSec: "100Mi"
            totalMaxConnections: 3000
            maxDataRetentionSize: "1000Gi"
            maxPartitions: 1500
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 100
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 1
            quotaType: "RHOSAK"
            capacityConsumed: 1
            supportedAZModes:
            - multi
            maturityStatus: stable
          - id: x2
            display_name: "2"
            ingressThroughputPerSec: "100Mi"
            egressThroughputPerSec: "200Mi"
            totalMaxConnections: 6000
            maxDataRetentionSize: "2000Gi"
            maxPartitions: 3000
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 200
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 2
            quotaType: "RHOSAK"
            capacityConsumed: 2
            supportedAZModes:
            - multi
            maturityStatus: preview

      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
              supported_instance_type:
                standard:
                  limit: 7
                developer:
                  limit: 30

      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: manual

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: Stage Cluster (In OSD Prod)
          cluster_id: 1lfl3g1vdea86ghh26vkmbqjkain900q
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true
          kafka_instance_limit: 37
          supported_instance_type: standard,developer

      SSO_SPECIAL_MANAGEMENT_ORG_ID: 13640203
  - namespace:
      $ref: /services/managed-services/namespaces/managed-services-production.yml
    # This commit sha will need to replaced to reference the latest working commit.
    # Make sure that we've a docker image for this before it can be changed.
    # Commits can be found here https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/commits/main
    # Inspect the recent merged MR from https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests?scope=all&utf8=%E2%9C%93&state=merged to get the latest commit that has a docker image built from it.
    # e.g if we take https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits, the commit with a docker image in it will be
    # the very first commit i.e https://gitlab.cee.redhat.com/service/kas-fleet-manager/-/merge_requests/356/commits?commit_id=f0fd63740464c5fa4bda395d5d31f675eff049ac
    # If in doubt, see with the control plane team.
    # We are exploring into using automating this.
    ref: 5ea97bf63bb65905c1d4f3bfe9d82c1176679183
    parameters:
      DB_SSLMODE: verify-full
      ENVIRONMENT: production
      KAFKA_LIFE_SPAN: 48
      QUOTA_TYPE: ams
      STRIMZI_OPERATOR_ADDON_ID: managed-kafka
      KAS_FLEETSHARD_ADDON_ID: kas-fleetshard-operator
      SENTRY_URL: sentry.devshift.net
      SENTRY_PROJECT: 16
      MAS_SSO_BASE_URL: https://identity.api.openshift.com
      MAS_SSO_REALM: rhoas
      OSD_IDP_MAS_SSO_REALM: rhoas-kafka-sre
      # Log level
      GLOG_V: 5
      # Image to be used by Envoy sidecar container
      ENVOY_IMAGE: quay.io/rhoas/envoyproxy:v1.20.2
      # The Cluster Logging Operator ID. An empty string indicates that the operator should not be installed.
      CLUSTER_LOGGING_OPERATOR_ADDON_ID: "cluster-logging-operator"
      OCM_URL: ${OCM_BASE_URL}
      AMS_URL: ${OCM_BASE_URL}
      # The browser url for the Streams for Apache Kafka console
      BROWSER_URL: ${CONSOLE_BASE_URL}/application-services/streams/kafkas/
      # Max allowed service accounts created by an organization
      MAX_ALLOWED_SERVICE_ACCOUNTS: 50
       # Max limit for the fetching the clients from mas-sso
      MAX_LIMIT_FOR_SSO_GET_CLIENTS: 100
      REPLICAS: 6
      # Dex identity service url
      DEX_URL: https://dex-dex.apps.mk-observe.trii.p1.openshiftapps.com
      # Dex identity service username
      DEX_USERNAME: admin@example.com
      # A URL to an Observatorium instance where observability metrics will sent to.
      OBSERVATORIUM_GATEWAY: https://observatorium-observatorium.apps.mk-observe.trii.p1.openshiftapps.com
      # Observatorium tenant where observability metrics will sent to.
      OBSERVATORIUM_TENANT: kasdataplane
      # The value of this auth type ( "dex" or "redhat" ) will determine the auth type ( Dex or Red Hat SSO) implemented for the observability
      OBSERVATORIUM_AUTH_TYPE: redhat
      # Token Refresher URL
      OBSERVATORIUM_TOKEN_REFRESHER_URL: http://token-refresher.managed-services-production.svc.cluster.local
      # Observatorium Red Hat SSO tenant for observability stack
      OBSERVATORIUM_RHSSO_TENANT: managedkafka
      # Red Hat SSO Observability gateway
      OBSERVATORIUM_RHSSO_GATEWAY: https://observatorium-mst.api.openshift.com
      # Red Hat SSO Observability realm
      OBSERVATORIUM_RHSSO_REALM: redhat-external
      # Red Hat SSO Observability auth server url
      OBSERVATORIUM_RHSSO_AUTH_SERVER_URL: https://sso.redhat.com/auth
      # Release tag within Config Repo to use for pulling index information
      OBSERVABILITY_CONFIG_TAG: v1.31.0
      # Maximum number of partitions per cluster
      KAFKA_CAPACITY_MAX_PARTITIONS: "1000"
      # A list of usernames representing users who do not have access to the service
      DENIED_USERS: []
      # A list of users with read-only permissions for data plane clusters
      READ_ONLY_USERS:
        - "dffrench"
        - "dimaggio"
        - "dingham"
        - "ebernard"
        - "gryan"
        - "jmadigan"
        - "jmernin"
        - "kwall"
        - "mchitimb"
        - "medgar"
        - "msoriano"
        - "pbraun"
        - "pemuir"
        - "ppaszki"
        - "ppatiern"
        - "rareddy"
        - "rgodfrey"
        - "shawkins"
        - "swoodman"
        - "tcooper"
        - "xiwu"
        - "lclarkeh"
        - "sbarker"
        - "kchernou"
        - "srbiswas"
        - "vbusch"
        - "lukchen"
        - "kstanley"
        - "aabdelre"
      # CEE Engineers
        - "aboucham"
        - "agagliar"
        - "asouza"
        - "cpandey"
        - "dhawkins"
        - "fvaleri"
        - "hnaram"
        - "jsherman"
        - "kboone"
        - "kkakarla"
        - "mmurphy"
        - "qluo"
        - "shiggs"
        - "toross"
      # A list of kafka-sre users with cluster-admin permissions for data plane clusters
      KAFKA_SRE_USERS:
        - "agullon"
        - "davmarti"
        - "rlawton"
        - "robrien"
        - "rshelly"
        - "stobin"
        - "tdavidso"
        - "npecka"
        - "fvila"
        - "mfreer"
        - "crarobin"
        - "pcremin"
        - "deepshar"
        - "hlipsig"
        - "raananda"
        - "sclarkso"
        - "jsarnovs"

      # parameters for SUPPORTED_INSTANCE_TYPES
      SUPPORTED_INSTANCE_TYPES:
      - id: developer
        display_name: "Trial"
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "1Mi"
            egressThroughputPerSec: "1Mi"
            totalMaxConnections: 100
            maxDataRetentionSize: "10Gi"
            maxPartitions: 100
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 50
            maxMessageSize: "1Mi"
            minInSyncReplicas: 1
            replicationFactor: 1
            quotaConsumed: 1
            quotaType: "RHOSAKTrial"
            capacityConsumed: 1
            supportedAZModes:
              - single
            lifespanSeconds: 172800
            maturityStatus: stable
      - id: standard
        display_name: "Standard"
        sizes:
          - id: x1
            display_name: "1"
            ingressThroughputPerSec: "50Mi"
            egressThroughputPerSec: "100Mi"
            totalMaxConnections: 3000
            maxDataRetentionSize: "1000Gi"
            maxPartitions: 1500
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 100
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 1
            quotaType: "RHOSAK"
            capacityConsumed: 1
            supportedAZModes:
              - multi
            maturityStatus: stable
          - id: x2
            display_name: "2"
            ingressThroughputPerSec: "100Mi"
            egressThroughputPerSec: "200Mi"
            totalMaxConnections: 6000
            maxDataRetentionSize: "2000Gi"
            maxPartitions: 3000
            maxDataRetentionPeriod: "P14D"
            maxConnectionAttemptsPerSec: 200
            maxMessageSize: "1Mi"
            minInSyncReplicas: 2
            replicationFactor: 3
            quotaConsumed: 2
            quotaType: "RHOSAK"
            capacityConsumed: 2
            supportedAZModes:
              - multi
            maturityStatus: preview

      # Set domain name for Kafka instances
      KAFKA_DOMAIN_NAME: "bf2.kafka.rhcloud.com"

      # A list of supported cloud providers and region
      SUPPORTED_CLOUD_PROVIDERS:
        - name: aws
          default: true
          regions:
            - name: us-east-1
              default: true
              supported_instance_type:
                standard: {}
                developer: {}
            - name: eu-west-1
              default: false
              supported_instance_type:
                standard: {}

      # Changing this to true will delete all kafkas after their lifespan expired. The default is 48 hours.
      ENABLE_KAFKA_LIFE_SPAN: true

      #manual: use data plane config file, auto: use kas-fleet-shard
      DATAPLANE_CLUSTER_SCALING_TYPE: manual

      # cluster list if dataplane cluster scaling type is set to manual
      CLUSTER_LIST:
        - name: mk-0419-204008
          cluster_id: 1k5ot6e86c6itcqqsrs019bngqc7cjin
          cloud_provider: aws
          region: us-east-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 27 # change this to match any value of configuration
          supported_instance_type: standard
        - name: mk-1006-115633
          cluster_id: 1nlj5j786fsg44srlj7f2kep5htakcp7
          cloud_provider: aws
          region: eu-west-1
          multi_az: true
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 3 # change this to match any value of configuration
          supported_instance_type: standard
        - name: mk-0503-013202
          cluster_id: 1rv3g4iu2m4jqsh8agh5lphl9cgqbb0p
          cloud_provider: aws
          region: us-east-1
          multi_az: false
          schedulable: true # change this to false if you do not want the cluster to be schedulable
          kafka_instance_limit: 50 # change this to match any value of configuration
          supported_instance_type: developer

      SSO_SPECIAL_MANAGEMENT_ORG_ID: 14410147

      # Skip list for Org IDs  for whom "MAX_ALLOWED_SERVICE_ACCOUNTS" limits dont apply
      SERVICE_ACCOUNT_LIMIT_CHECK_SKIP_ORG_ID_LIST:
        - "1979710"
        - "6340056"
        - "11009103"
