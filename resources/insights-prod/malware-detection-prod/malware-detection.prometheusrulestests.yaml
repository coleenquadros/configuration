---
$schema: /app-interface/prometheus-rule-test-1.yml

rule_files:
- /insights-prod/malware-detection-prod/malware-detection.prometheusrules.yaml

evaluation_interval: 1m

tests:
# MalwareDetectionDownInProd
- interval: 1m
  input_series:
  - series: up{service="malware-detection-api", namespace="malware-detection-prod", pod="malware-detection-api-1"}
    values: 1+0x4 0+0x4 1+0x4  # = 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 (which are the values of the 'up' metric at each 'minute')
  - series: up{service="malware-detection-api", namespace="malware-detection-prod", pod="malware-detection-api-2"}
    values: 1+0x4 0+0x4 1+0x4
  - series: up{service="malware-detection-api", namespace="malware-detection-prod", pod="malware-detection-api-3"}
    values: 1+0x4 0+0x4 1+0x4
  alert_rule_test:
  - alertname: MalwareDetectionDownInProd
    # expect no alert at 9 mins because up = 0 for only 4 consecutive minutes then
    eval_time: 9m
    exp_alerts: []
  alert_rule_test:
  - alertname: MalwareDetectionDownInProd
    # expect an alert at 10 mins because up = 0 for 5 consecutive minutes then
    eval_time: 10m
    exp_alerts:
      - exp_labels:
          severity: high
          service: insights
          env: prod
          app_team: malware-detection
          namespace: malware-detection-prod
        exp_annotations:
          message: "All pods are down in malware-detection-prod"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/malware-detection-prod/pods"
          dashboard: https://grafana.app-sre.devshift.net/d/FSmSIdH7z/malware-detection?orgId=1&refresh=5s&var-datasource=crcp01ue1-prometheus&from=now-6h&to=now
          runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/blob/master/docs/console.redhat.com/app-sops/malware-detection/MalwareDetectionDownInProd.md"
  alert_rule_test:
  - alertname: MalwareDetectionDownInProd
    # expect no alert at 11 mins because pods are all up again
    eval_time: 11m
    exp_alerts: []
  alert_rule_test:
  - alertname: MalwareDetectionPodsDownInProd
    # However alert for MalwareDetectionPodsDownInProd at 15 mins because avg up < 0.9 over last 10 minutes
    eval_time: 15m
    exp_alerts:
      - exp_labels:
          severity: medium
          service: insights
          env: prod
          app_team: malware-detection
          namespace: malware-detection-prod
        exp_annotations:
          message: "Pod(s) down in malware-detection-prod"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/malware-detection-prod/pods"
          dashboard: https://grafana.app-sre.devshift.net/d/FSmSIdH7z/malware-detection?orgId=1&refresh=5s&var-datasource=crcp01ue1-prometheus&from=now-6h&to=now
          runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/blob/master/docs/console.redhat.com/app-sops/malware-detection/MalwareDetectionPodsDownInProd.md"

# MalwareDetectionPodsDownInProd
- interval: 1m
  input_series:
  - series: up{service="malware-detection-api", namespace="malware-detection-prod", pod="malware-detection-api-1"}
    values: 1+0x20 # the value of up for 21 'minutes' for this pod
  - series: up{service="malware-detection-api", namespace="malware-detection-prod", pod="malware-detection-api-2"}
    values: 1+0x20 # the value of up for 21 'minutes' for this pod
  - series: up{service="malware-detection-api", namespace="malware-detection-prod", pod="malware-detection-api-3"}
    values: 1 0+0x9 1+0x9  # = 1 0 0 0 0 0 0 0 0 0 0 1 ... (which are the values of the 'up' metric at each 'minute')
  alert_rule_test:
  - alertname: MalwareDetectionPodsDownInProd
    # no alert at 10 mins because avg up hasn't been < 0.9 for 10 minutes yet
    eval_time: 10m
    exp_alerts: []
  alert_rule_test:
  - alertname: MalwareDetectionDownInProd
    # expect no alert for MalwareDetectionDownInProd because not all pods are down
    eval_time: 11m
    exp_alerts: []
  alert_rule_test:
  - alertname: MalwareDetectionPodsDownInProd
    # However alert for MalwareDetectionPodsDownInProd at 11 mins because avg up < 0.9 over 10 consecutive minutes
    eval_time: 11m
    exp_alerts:
      - exp_labels:
          severity: medium
          service: insights
          env: prod
          app_team: malware-detection
          namespace: malware-detection-prod
        exp_annotations:
          message: "Pod(s) down in malware-detection-prod"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/malware-detection-prod/pods"
          dashboard: https://grafana.app-sre.devshift.net/d/FSmSIdH7z/malware-detection?orgId=1&refresh=5s&var-datasource=crcp01ue1-prometheus&from=now-6h&to=now
          runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/blob/master/docs/console.redhat.com/app-sops/malware-detection/MalwareDetectionPodsDownInProd.md"
  alert_rule_test:
  - alertname: MalwareDetectionPodsDownInProd
    # still alert at 12 mins because avg up over time for the last 10 minutes is still < 0.9
    eval_time: 12m
    exp_alerts:
      - exp_labels:
          severity: medium
          service: insights
          env: prod
          app_team: malware-detection
          namespace: malware-detection-prod
        exp_annotations:
          message: "Pod(s) down in malware-detection-prod"
          link_url: "https://console-openshift-console.apps.crcp01ue1.o9m8.p1.openshiftapps.com/k8s/ns/malware-detection-prod/pods"
          dashboard: https://grafana.app-sre.devshift.net/d/FSmSIdH7z/malware-detection?orgId=1&refresh=5s&var-datasource=crcp01ue1-prometheus&from=now-6h&to=now
          runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/blob/master/docs/console.redhat.com/app-sops/malware-detection/MalwareDetectionPodsDownInProd.md"
  alert_rule_test:
    # no alert at 20 mins because avg up over time for the last 10 minutes is >= 0.9
  - alertname: MalwareDetectionPodsDownInProd
    eval_time: 20m
    exp_alerts: []

# MalwareDetection5xxInProd
- interval: 1m
  input_series:
  - series: http_request_duration_seconds_count{service="malware-detection-api", namespace="malware-detection-prod", status_code="500"}
    values: 1+0x4 1+1x5  # (which are the values of the 'http_request_duration_seconds_count' metric at each 'minute')
  alert_rule_test:
  - alertname: MalwareDetection5xxInProd
    # no alert at 5 mins because the rate of 500s will have dropped to 0 by now
    eval_time: 5m
    exp_alerts: []
  - alertname: MalwareDetection5xxInProd
    # no alert at 10 mins because the rate of 500s needs to be > 0 for at least 5 minutes before the alert fires
    eval_time: 10m
    exp_alerts: []
  - alertname: MalwareDetection5xxInProd
    # alert at 11 mins because the rate of 500s has been above 0 for at least 5 minutes now
    eval_time: 11m
    exp_alerts:
      - exp_labels:
          severity: medium
          service: insights
          env: prod
          app_team: malware-detection
          namespace: malware-detection-prod
        exp_annotations:
          message: "5xx responses observed in malware-detection-prod"
          dashboard: https://grafana.app-sre.devshift.net/d/FSmSIdH7z/malware-detection?orgId=1&refresh=5s&var-datasource=crcp01ue1-prometheus&from=now-6h&to=now
          runbook: "https://gitlab.cee.redhat.com/service/app-interface/-/blob/master/docs/console.redhat.com/app-sops/malware-detection/MalwareDetection5xxInProd.md"
          link_url: "https://kibana.apps.crcp01ue1.o9m8.p1.openshiftapps.com/app/kibana#/discover?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-1h,to:now))&_a=(columns:!(_source),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'43c5fed0-d5ce-11ea-b58c-a7c95afd7a5d',key:'@log_group',negate:!f,params:(query:malware-detection-prod),type:phrase),query:(match_phrase:('@log_group':malware-detection-prod)))),index:'43c5fed0-d5ce-11ea-b58c-a7c95afd7a5d',interval:auto,query:(language:kuery,query:'%22statusCode:500%22'),sort:!())"
