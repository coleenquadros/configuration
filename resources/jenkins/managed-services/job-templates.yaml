- job-template:
    id: gl-pr-check-managed-services
    name: "{gl_group}-{gl_project}-gl-pr-check"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *app_interface_creds
            - *quay_secret_push
            - *ci_ocm_token
            - *ci_aws_keys
    <<: *gl_pr_check
    artifacts_path: 'test-results/**'
    publishers:
    - gitlab_message:
        <<: *gitlab_message_defaults
    - gitlab-notifier
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true

- job-template:
    id: gl-build-master-managed-services
    name: "{gl_group}-{gl_project}-gl-build-{branch}"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - vault-secrets:
          <<: *vault_defaults
          secrets:
          - *ci_jenkins_token
          - *cpaas_rhosak_token
          - *gitlab_token
          - *backup_ecr_push_creds
          - *quay_secret_push
          - *app_sre_bot_push_token
          - *app_interface_creds
          - *managed_services_github_deploy_key
          - *rhoas-quay-access
          - *ci_cd_quay
    <<: *gl_build_master

- job-template:
    id: managed-services-gl-build-test-branch
    name: "{gl_group}-{gl_project}-gl-build-test-{branch}"
    wrappers:
      - timeout_wrapper:
          timeout: 360
      - vault-secrets:
          <<: *vault_defaults
          secrets:
          - *ci_jenkins_token
          - *cpaas_rhosak_token
          - *gitlab_token
          - *backup_ecr_push_creds
          - *quay_secret_push
          - *app_sre_bot_push_token
          - *app_interface_creds
          - *managed_services_github_deploy_key
          - *ci_ocm_token
          - *ci_aws_keys
          - *ci_cd_quay
          - *managed_services_reportportal
    <<: *gl_build_master
    parameters:
    - bool:
        name: RELEASE
        default: '{release}'
        description: 'indicates release build'
    - choice:
        name: TEST_STRATEGY
        description: 'Strimzi Operators system tests to be executed'
        choices:
            - acceptance
            - minimal
            - regression
    - bool:
        name: TEMP_CPAAS_BUILD
        default: 'true'
        description: 'whether to use scratch=true in CPaaS build'
    - bool:
        name: SKIP_BUILD
        default: 'false'
        description: 'true if you want to skip CPaaS build and use snapshot images defined in build_config.yaml for testing/releasing'
    - string:
        name: CPAAS_BUILD
        default: ''
        description: 'if you want to use existing CPaaS build (avoid triggering new build)'
    - bool:
        name: CLUSTER_CLEANUP
        default: 'true'
        description: 'include deletion of test cluster'
    publishers:
    - archive:
        artifacts: "{archive_artifacts}"
        allow-empty: true
    - junit:
        results: "{junit_results}"
        allow-empty-results: true
    - postbuildscript:
        builders:
            - role: SLAVE
              build-on:
                - NOT_BUILT
                - ABORTED
                - FAILURE
              build-steps:
                - shell: "{cleanup_script}"

- job-template:
    id: mk-nightly-build-test-branch
    name: "{gl_group}-{gl_project}-gl-build-test-nightly-{branch}"
    wrappers:
      - timeout_wrapper:
          timeout: 360
      - vault-secrets:
          <<: *vault_defaults
          secrets:
          - *ci_jenkins_token
          - *gitlab_token
          - *backup_ecr_push_creds
          - *quay_secret_push
          - *app_sre_bot_push_token
          - *app_interface_creds
          - *managed_services_github_deploy_key
          - *ci_ocm_token
          - *ci_aws_keys
          - *ci_cd_quay
          - *managed_services_reportportal
    <<: *gl_timed
    publishers:
    - archive:
        artifacts: "{archive_artifacts}"
        allow-empty: true
    - junit:
        results: "{junit_results}"
    - postbuildscript:
        builders:
            - role: SLAVE
              build-on:
                - NOT_BUILT
                - ABORTED
                - FAILURE
              build-steps:
                - shell: "{cleanup_script}"

- job-template:
    id: managed-services-pull-upstream
    name: 'managed-services-pull-upstream'
    description: "[managed-services] pull changes from all upstreams specified in {gl_group}/{gl_project}/script/repo-config.yaml"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *app_sre_bot_push_token
            - *managed_services_github_deploy_key
    publishers:
      - <<: *slack_notify
    <<: *gl_timed

- job-template:
    id: managed-services-merge-pulled-upstreams
    name: 'managed-services-merge-pulled-upstreams'
    description: "[managed-services] merge pulled changes from all upstreams specified in {gl_group}/{gl_project}/script/repo-config.yaml"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *app_sre_bot_push_token
    publishers:
      - <<: *slack_notify
    <<: *gl_timed

- job-template:
    id: 'managed-services-pull-upstream-tag'
    name: 'managed-services-pull-upstream-tag'
    description: "[managed-services] pull upstream tag for specified project (that must be specified in {gl_group}/{gl_project}/script/repo-config.yaml)"
    wrappers:
    - timestamps
    - timeout_wrapper:
        timeout: '{timeout}'
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
          - *app_sre_bot_push_token
          - *managed_services_github_deploy_key
    parameters:
    - string:
        name: PROJECT_NAME
        default: ''
        description: 'project name, has to be the same as in config file'
    - string:
        name: UPSTREAM_TAG
        default: ''
        description: 'tag name, e.i. upstream release version'
    - string:
        name: PREVIOUS_RELEASE_BRANCH
        default: ''
        description: '(optional) name of the branch to import the ci-cd files from'
    <<: *gl_checkout
    builders:
      - shell: "{ci_cmd}"

- job-template:
    id: 'managed-services-prepare-cpaas-pipelines'
    name: 'managed-services-prepare-cpaas-pipelines'
    description: "[managed-services] prepare CPaaS pipelines for specified project (that must be specified in {gl_group}/{gl_project}/script/repo-config.yaml)"
    wrappers:
    - timestamps
    - timeout_wrapper:
        timeout: '{timeout}'
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
          - *app_sre_bot_push_token
    parameters:
    - choice:
        name: PROJECT_NAME
        description: 'currently supported projects (those which have templates in *-pipeline-configs and cpaas-products/rhosak repos)'
        choices:
            - kas-fleetshard
            - kafka-admin-api
            - mk-strimzi-kafka
            - strimzi-canary
            - strimzi-drain-cleaner
    - string:
        name: RHOSAK_VERSION
        default: ''
        description: 'version of related rhosak bundle'
    - string:
        name: RELEASE_VERSION
        default: ''
        description: 'version of the project'
    - bool:
        name: PREPARE_PIPELINE_CONFIGS
        default: true
        description: "prepare *-pipeline-configs for the project & version"
    - bool:
        name: PREPARE_CPAAS_PRODUCTS
        default: true
        description: "prepare cpaas-products/rhosak for the project & version"
    <<: *gl_checkout
    builders:
      - shell: "{ci_cmd}"

- job-template:
    id: 'managed-services-patch-latest-midstream'
    name: 'managed-services-patch-latest-midstream'
    description: "[managed-services] patches (tag with next sequence) latest commit on midstream for specified project and updates CPaaS configs (project must be specified in {gl_group}/{gl_project}/script/repo-config.yaml)"
    wrappers:
    - timestamps
    - timeout_wrapper:
        timeout: '{timeout}'
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
          - *app_sre_bot_push_token
    parameters:
    - choice:
        name: PROJECT_NAME
        description: 'currently supported projects (those which have templates in *-pipeline-configs repo)'
        choices:
            - kas-fleetshard
            - kafka-admin-api
            - strimzi-canary
            - strimzi-drain-cleaner
    - string:
        name: RELEASE_VERSION
        default: ''
        description: 'version of the project that will be patched'
    <<: *gl_checkout
    builders:
      - shell: "{ci_cmd}"

- job-template:
    id: 'managed-kafka-performance'
    name: 'managed-kafka-performance-{mk_perf_type}'
    wrappers:
    - timestamps
    - timeout_wrapper:
        timeout: '{timeout}'
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
        - *ci_ocm_token
        - *ci_aws_keys
    parameters:
    - string:
        name: TESTCASE
        default: '{mk_perf_test}'
        description: 'maven parameter for executing specific tests'
    - string:
        name: KAFKA_WORKER_COUNT
        default: '17'
        description: 'count of worker nodes for kafka cluster'
    - string:
        name: OMB_WORKER_COUNT
        default: '10'
        description: 'count of worker nodes for OMB cluster'
    - string:
        name: OMB_TEST_DURATION
        default: 'PT1M'
        description: 'OMB test duration in minutes, minimum 1 min'
    - string:
        name: OMB_WARMUP_DURATION
        default: 'PT1M'
        description: 'OMB warmup duration in minutes, minimum 1 min'
    - string:
        name: FLAVOR
        default: 'm5.4xlarge'
        description: 'OSD aws node flavor'
    - string:
        name: REGION
        default: 'us-east-2'
        description: 'OSD aws region'
    - string:
        name: MULTI_AZ
        default: 'false'
        description: 'aws multi availablility for osd cluster'
    - string:
        name: OMB_COLLECT_LOG
        default: 'true'
        description: 'collect logs from OMB framework'
    <<: *gl_checkout
    builders:
      - shell: "make ci/pipeline"
    publishers:
    - archive:
        artifacts: 'target/logs/**,target/surefire-reports/**'
        allow-empty: true
    - junit:
        results: 'target/surefire-reports/*.xml'
    - <<: *slack_notify
    - postbuildscript:
        builders:
            - role: SLAVE
              build-on:
                - NOT_BUILT
                - ABORTED
                - FAILURE
              build-steps:
                - shell: "make ci/pipeline/cleanup"

- job-template:
    id: managed-services-security-scan
    name: "{gl_project}-security-scan-{branch}"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *mk_security_scan_token
    <<: *gl_timed
    publishers:
    - archive:
        artifacts: 'logs/*.txt'
        allow-empty: true
    - <<: *slack_notify

- job-template:
    id: managed-kafka-fault-tests-manual
    name: "{display_name}"
    wrappers:
      - timestamps
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *ci_test_token
            - *rhosak_tests_tokens
            - *aws_rhosak_1
    concurrent: true
    parameters:
    - string:
        name: BRANCH
        default: '{default_branch}'
        description: 'The branch of kas-fault-tests repo you want to run the pipeline against. Defaults to main'
    - string:
        name: OPENSHIFT_VERSION
        default: '4.8.15'
        description: 'The version of openshift to be used when deploying the OSD cluster. Default 4.8.15'
    - string:
        name: OCM_CLUSTER_NAME
        default: ''
        description: 'OSD cluster name (if not defined, a random name will be set), max name length is 14 characters. If the cluster already exists, it will be used. Otherwise, it will be provisioned'
    - string:
          name: KAFKA_INSTANCE_NAME
          default: 'kafka-instance'
          description: 'The namespace of an existing Kafka instance you want to run the pipeline against. Not required if the pipeline is installing Kafka using the INSTALL_KAFKA parameter'
    - string:
          name: COMPUTE_NODES_COUNT
          default: '3'
          description: '[REQUIRED] OSD worker nodes for kafka cluster. If you select multi-az you must have a multiple of 3 for COMPUTE_NODES_COUNT'
    - choice:
        name: COMPUTE_MACHINE_TYPE
        description: '[REQUIRED] node type of cluster compute nodes'
        choices:
            - m5.4xlarge
            - m5.2xlarge
            - m5.xlarge
    - choice:
        name: OCM_CLUSTER_REGION
        description: '[REQUIRED] AWS region for the OSD cluster. If executing cloud layer tests, ensure that the cluster is in a region where no other clusters are deployed'
        choices:
            - us-east-1
            - us-east-2
            - us-west-1
            - us-west-2
            - ap-south-1
            - ap-northeast-1
            - ap-northeast-2
            - ap-northeast-3
            - ap-southeast-1
            - ap-southeast-2
            - ca-central-1
            - eu-central-1
            - eu-west-1
            - eu-west-2
            - eu-west-3
            - eu-north-1
            - sa-east-1
    - bool:
        name: MULTI_AZ
        default: true
        description: If true the cluster will be provisioned with multiple AZ, if false for only one AZ
    - bool:
        name: DEPROVISION_CLUSTER
        default: false
        description: If true the provisioned or provided cluster will be deleted
    - bool:
        name: INSTALL_KAFKA
        default: true
        description: If true a kafka instance will be installed in the cluster
    - choice:
        name: TEST_LAYER
        description: '[REQUIRED] Select the set of tests to be executed'
        choices:
          - all
          - none
          - cloud
          - openshift
          - kafka
    branch: '${{BRANCH}}'
    <<: *gh_checkout
    builders:
      - shell: |
          ./pipeline/fault_pipeline.sh
    artifacts_path: 'fault-results/**'
    publishers:
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true
    - <<: *slack_notify

- job-template:
    id: managed-kafka-fault-tests-nightly
    name: "{display_name}"
    wrappers:
      - timestamps
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *ci_test_token
            - *rhosak_tests_tokens
            - *aws_rhosak_1
    concurrent: true
    parameters:
    - string:
        name: BRANCH
        default: '{default_branch}'
        description: 'The branch of kas-fault-tests repo you want to run the pipeline against. Defaults to main'
    - string:
        name: OPENSHIFT_VERSION
        default: '4.8.15'
        description: 'The version of openshift to be used when deploying the OSD cluster. Default 4.8.15'
    - string:
        name: OCM_CLUSTER_NAME
        default: ''
        description: 'OSD cluster name (if not defined, a random name will be set), max name length is 14 characters. If the cluster already exists, it will be used. Otherwise, it will be provisioned'
    - string:
          name: KAFKA_INSTANCE_NAME
          default: 'kafka-instance'
          description: 'The namespace of an existing Kafka instance you want to run the pipeline against. Not required if the pipeline is installing Kafka using the INSTALL_KAFKA parameter'
    - string:
          name: COMPUTE_NODES_COUNT
          default: '3'
          description: '[REQUIRED] OSD worker nodes for kafka cluster. If you select multi-az you must have a multiple of 3 for COMPUTE_NODES_COUNT'
    - choice:
        name: COMPUTE_MACHINE_TYPE
        description: '[REQUIRED] node type of cluster compute nodes'
        choices:
            - m5.4xlarge
            - m5.2xlarge
            - m5.xlarge
    - choice:
        name: OCM_CLUSTER_REGION
        description: '[REQUIRED] AWS region for the OSD cluster. If executing cloud layer tests, ensure that the cluster is in a region where no other clusters are deployed'
        choices:
            - us-east-2
            - us-east-1
            - us-west-1
            - us-west-2
            - ap-south-1
            - ap-northeast-1
            - ap-northeast-2
            - ap-northeast-3
            - ap-southeast-1
            - ap-southeast-2
            - ca-central-1
            - eu-central-1
            - eu-west-1
            - eu-west-2
            - eu-west-3
            - eu-north-1
            - sa-east-1
    - bool:
        name: MULTI_AZ
        default: true
        description: If true the cluster will be provisioned with multiple AZ, if false for only one AZ
    - bool:
        name: DEPROVISION_CLUSTER
        default: true
        description: If true the provisioned or provided cluster will be deleted
    - bool:
        name: INSTALL_KAFKA
        default: true
        description: If true a kafka instance will be installed in the cluster
    - choice:
        name: TEST_LAYER
        description: '[REQUIRED] Select the set of tests to be executed'
        choices:
          - all
          - none
          - cloud
          - openshift
          - kafka
    branch: '${{BRANCH}}'
    <<: *gh_timed
    builders:
      - shell: |
          ./pipeline/fault_pipeline.sh
    artifacts_path: 'fault-results/**'
    publishers:
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true
    - <<: *slack_notify

- job-template:
    id: managed-kafka-perf-tests
    name: "managed-kafka-perf-tests"
    wrappers:
      - timestamps
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *ci_test_token
            - *rhosak_tests_tokens
            - *aws_rhosak_1
            - *github_token
    concurrent: true
    parameters:
    - string:
        name: BRANCH
        default: '{default_branch}'
        description: 'The branch of mk-performance-tests repo you want to run the pipeline against. Defaults to master'
    - string:
        name: OPENSHIFT_VERSION
        default: ''
        description: 'The version of openshift to be used when deploying the OSD cluster. Default latest (empty)'
    - string:
        name: TESTCASE
        default: 'io.kafka.performance.KafkaInstanceScalingSmallTestDecoupled#testClusterMaxKafkaValueProdBinPacking'
        description: 'maven parameter for executing specific tests'
    - string:
        name: KAFKA_CLUSTER_NAME
        default: ''
        description: 'OSD cluster name (if not defined, a random name will be set), max name length is 14 characters. If the cluster already exists, it will be used. Otherwise, it will be provisioned'
    - string:
        name: KAFKA_OSD_CLUSTER_CONFIG
        default: 'COMPUTE_NODES_COUNT=6,
         COMPUTE_MACHINE_TYPE=m5.4xlarge,
         OCM_CLUSTER_REGION=us-east-2,
         MULTI_AZ=true'
        description: 'The variables needed to provision an OSD where kafka will be installed'
    - string:
        name: OMB_CLUSTER_NAME
        default: ''
        description: 'OSD cluster name (if not defined, a random name will be set), max name length is 14 characters. If the cluster already exists, it will be used. Otherwise, it will be provisioned'
    - string:
        name: OMB_OSD_CLUSTER_CONFIG
        default: 'COMPUTE_NODES_COUNT=2,
         COMPUTE_MACHINE_TYPE=m5.4xlarge,
         OCM_CLUSTER_REGION=us-east-2,
         MULTI_AZ=false'
        description: 'The variables needed to provision an OSD where OMB will be installed'
    - string:
        name: NUMBER_OF_KAFKA_INSTANCES
        default: '1'
    - string:
        name: KAFKA_INSTANCE_NAME
        default: 'instance'
        description: 'The namespace of an existing Kafka instance you want to run the pipeline against. If there are more than one instace, a random string will be suffixed'
    - string:
        name: KAFKA_CAPACITY_CONFIG
        default: 'INGRESS_THROUGHPUT=30Mi,
         TOTAL_MAX_CONNECTIONS=500,
         MAX_DATA_RETENTION_SIZE=1000Gi,
         MAX_PARTITIONS=500,
         MAX_DATA_RETENTION_PERIOD=P14D,
         MAX_CONNECTION_ATTEMPTS_PER_SEC=100'
        description: 'The variables needed to configure the kafka installation'
    - string:
        name: TEST_EXECUTION_CONFIG
        default: 'OMB_TEST_DURATION=PT15M,
         TARGET_RATE=15,
         WORKERS_PER_INSTANCE=2,
         TOPICS_PER_KAFKA=1,
         PRODUCERS_PER_TOPIC=1,
         PAYLOAD_FILE_SIZE=512Ki,
         PARTITIONS_PER_TOPIC=9,
         SUBSCRIPTIONS_PER_TOPIC=1,
         CONSUMER_PER_SUBSCRIPTION=1'
        description: 'The variables needed to configure the test case to be executed'
    - bool:
        name: DEPROVISION_CLUSTER
        default: true
        description: If true the provisioned or provided cluster will be deleted
    branch: '${{BRANCH}}'
    <<: *gl_checkout
    builders:
      - shell: |
          ./scripts/pipeline_kas_perf_tests.sh
    artifacts_path: 'target/logs/**, output_charts/**'
    publishers:
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true
    - <<: *slack_notify

- job-template:
    id: managed-kafka-perf-tests-1hr-integration
    name: "managed-kafka-perf-tests-1hr-integration"
    wrappers:
      - timestamps
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *ci_test_token
            - *rhosak_tests_tokens
            - *aws_rhosak_3
            - *github_token
    concurrent: true
    parameters:
    - string:
        name: BRANCH
        default: '{default_branch}'
        description: 'The branch of mk-performance-tests repo you want to run the pipeline against. Defaults to master'
    - string:
        name: OPENSHIFT_VERSION
        default: '4.8.15'
        description: 'The version of openshift to be used when deploying the OSD cluster. Default 4.8.15'
    - string:
        name: TESTCASE
        default: 'io.kafka.performance.KafkaInstanceScalingSmallTestDecoupled#testClusterMaxKafkaValueProdBinPacking'
        description: 'maven parameter for executing specific tests'
    - string:
        name: KAFKA_CLUSTER_NAME
        default: ''
        description: 'OSD cluster name (if not defined, a random name will be set), max name length is 14 characters. If the cluster already exists, it will be used. Otherwise, it will be provisioned'
    - string:
        name: KAFKA_OSD_CLUSTER_CONFIG
        default: 'COMPUTE_NODES_COUNT=6,
         COMPUTE_MACHINE_TYPE=m5.4xlarge,
         OCM_CLUSTER_REGION=us-east-2,
         MULTI_AZ=true'
        description: 'The variables needed to provision an OSD where kafka will be installed'
    - string:
        name: OMB_CLUSTER_NAME
        default: ''
        description: 'OSD cluster name (if not defined, a random name will be set), max name length is 14 characters. If the cluster already exists, it will be used. Otherwise, it will be provisioned'
    - string:
        name: OMB_OSD_CLUSTER_CONFIG
        default: 'COMPUTE_NODES_COUNT=2,
         COMPUTE_MACHINE_TYPE=m5.4xlarge,
         OCM_CLUSTER_REGION=us-east-2,
         MULTI_AZ=false'
        description: 'The variables needed to provision an OSD where OMB will be installed'
    - string:
        name: NUMBER_OF_KAFKA_INSTANCES
        default: '1'
    - string:
        name: KAFKA_INSTANCE_NAME
        default: 'instance'
        description: 'The namespace of an existing Kafka instance you want to run the pipeline against.'
    - string:
        name: KAFKA_CAPACITY_CONFIG
        default: 'INGRESS_THROUGHPUT=30Mi,
         TOTAL_MAX_CONNECTIONS=500,
         MAX_DATA_RETENTION_SIZE=1000Gi,
         MAX_PARTITIONS=500,
         MAX_DATA_RETENTION_PERIOD=P14D,
         MAX_CONNECTION_ATTEMPTS_PER_SEC=100'
        description: 'The variables needed to configure the kafka installation'
    - string:
        name: TEST_EXECUTION_CONFIG
        default: 'OMB_TEST_DURATION=PT60M,
         TARGET_RATE=15,
         WORKERS_PER_INSTANCE=2,
         TOPICS_PER_KAFKA=1,
         PRODUCERS_PER_TOPIC=1,
         PAYLOAD_FILE_SIZE=512Ki,
         PARTITIONS_PER_TOPIC=9,
         SUBSCRIPTIONS_PER_TOPIC=1,
         CONSUMER_PER_SUBSCRIPTION=1'
        description: 'The variables needed to configure the test case to be executed'
    - bool:
        name: DEPROVISION_CLUSTER
        default: true
        description: If true the provisioned or provided cluster will be deleted
    branch: '${{BRANCH}}'
    <<: *gl_checkout
    <<: *gl_timed
    builders:
      - shell: |
          ./scripts/pipeline_kas_perf_tests.sh
    artifacts_path: 'target/logs/**, output_charts/**'
    publishers:
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true
    - <<: *slack_notify

- job-template:
    id: aws-purge-velero-backup
    name: "aws-purge-velero-backup"
    parameters:
    - string:
        name: AWS_REGION
        default: 'us-east-1'
        description: 'The target AWS region for the velero_backups you want to remove.'
    wrappers:
      - timestamps
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *aws_rhosak_3
    <<: *gl_checkout
    builders:
      - shell: |
          ./scripts/purge_velero_backup.sh

- job-template:
    id: strimzi-operator-test
    name: "strimzi-operator-test"
    wrappers:
    - timestamps
    - timeout_wrapper:
        timeout: "{timeout}"
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
          - *app_interface_creds
          - *quay_secret_push
          - *ci_ocm_token
          - *ci_aws_keys
    parameters:
    - choice:
        name: TEST_GROUP
        choices:
          - acceptance
          - regression
          - smoke
          - acceptance,regression
          - acceptance,smoke
          - regression,smoke
          - acceptance,regression,smoke
        description: 'Select the test-group to be executed'
    - string:
        name: EXCLUDED_GROUPS
        default: 'loadbalancer,nodeport,connectcomponents,connectoperator,mirrormaker,bridge,cruisecontrol'
        description: 'Mention the test-group to be skipped'
    - string:
        name: OSD_CLUSTER_NAME
        default: 'sob-test-$BUILD_NUMBER'
        description: 'Name of the cluster to be provisioned'
    <<: *gl_checkout
    builders:
    - shell: ./pr_check.sh
    artifacts_path: 'test-results/**'
    publishers:
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true

- job-template:
    id: 'gl-build-master-strimzi'
    name: '{gl_group}-{gl_project}-gl-build-{branch}'
    wrappers:
        - vault-secrets:
            <<: *vault_defaults
            secrets:
            - *ci_jenkins_token
            - *gitlab_token
    <<: *gl_build_master

- job-template:
    id: 'kas-fleet-manager-tests'
    name: 'kas-fleet-manager-tests-stage'
    publishers:
    - <<: *slack_notify
    - archive:
        artifacts: 'data/results/**'
        allow-empty: true
    wrappers:
      - timeout_wrapper:
          timeout: '{timeout}'
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *kas_fleet_manager_int_tests
            - *quay_secret_pull
    <<: *gl_timed

- job-template:
    id: 'notification-payloads-pr-check'
    name: "{gl_group}-{gl_project}-gl-pr-check"
    wrappers:
      - timeout_wrapper:
          timeout: '{timeout}'
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *notification_payloads_pr_check
            - *gitlab_token
    <<: *gl_pr_check
    publishers:
    - gitlab_message:
        <<: *gitlab_message_defaults
    - gitlab-notifier

- job-template:
    id: 'notification-payloads-main-build'
    name: '{gl_group}-{gl_project}-gl-build-{branch}'
    wrappers:
        - vault-secrets:
            <<: *vault_defaults
            secrets:
            - *notification_payloads_main_build
            - *gitlab_token
    <<: *gl_build_master
    publishers:
    - gitlab_message:
        <<: *gitlab_message_defaults
    - gitlab-notifier

- job-template:
    id: kas-fleet-manager-perf-test
    name: kas-fleet-manager-perf-test-stage
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *kas_fleet_manager_perf_test_stage
    ci_cmd: './perf_test.sh'
    <<: *gl_timed
    publishers:
    - archive:
        artifacts: 'reports/**'
        allow-empty: true
    - <<: *slack_notify

- job-template:
    id: gl-pr-check-apache-kafka
    name: "{gl_group}-{gl_project}-gl-pr-check"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *app_interface_creds
            - *quay_secret_push
            - *ci_ocm_token
            - *ci_aws_keys
    <<: *gl_pr_check
    artifacts_path: 'clients/build/reports/tests/unitTest/*.html'
    publishers:
    - gitlab_message:
        <<: *gitlab_message_defaults
    - gitlab-notifier
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true

- job-template:
    id: managed-services-promote-ui
    name: managed-{ui}-promote-ui
    wrappers:
    - timestamps
    - timeout_wrapper:
        timeout: "{timeout}"
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
          - *managed_services_github_deploy_key
    parameters:
    - string:
        name: REPOSITORIES
        default: "{repositories}"
        description: 'All repositories to promote'
    - bool:
        name: DRY_RUN
        default: true
        description: If true the changes are not pushed
    <<: *gl_checkout
    builders:
    - shell: ./script/promote-ui.sh

- job-template:
    id: mas-sso-build-template
    name: "{gl_group}-{gl_project}-gl-build-{branch}"
    description: "mass-sso build template"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *rhoas-quay-access
            - *app_sre_bot_push_token
#    publishers:
#      - <<: *slack_notify
    <<: *gl_build_master

- job-template:
    id: gl-build-main-kas-fleet-manager
    name: "{gl_group}-{gl_project}-gl-build-{branch}"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - vault-secrets:
          <<: *vault_defaults
          secrets:
          - *quay_secret_push
          - *rhoas-quay-access
          - *kas_fleet_manager_pr_check
    <<: *gl_build_master

- job-template:
    id: gl-pr-check-kas-fleet-manager
    name: "{gl_group}-{gl_project}-gl-pr-check"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - vault-secrets:
          <<: *vault_defaults
          secrets:
          - *quay_secret_push
          - *rhoas-quay-access
          - *kas_fleet_manager_pr_check
    <<: *gl_pr_check

- job-template:
    id: 'gl-pr-check-mas-sso'
    name: '{gl_group}-{gl_project}-gl-pr-check'
    wrappers:
    - timeout_wrapper:
        timeout: '{timeout}'
    - ansicolor
    - vault-secrets:
        <<: *vault_defaults
        secrets:
        - *rhoas-quay-access
    <<: *gl_pr_check

- job-template:
    id: gl-pr-check-kas-upgrade-configurations
    name: "{gl_group}-{gl_project}-gl-pr-check"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *app_interface_creds
            - *quay_secret_push
            - *gitlab_token
            - *kas_fleet_manager_admin_staging
            - *kas_fleet_manager_admin_prod
    <<: *gl_pr_check
    publishers:
    - gitlab_message:
        <<: *gitlab_message_defaults
    - gitlab-notifier

- job-template:
    id: gl-build-main-kas-upgrade-configurations
    name: "{gl_group}-{gl_project}-gl-build-{branch}"
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *app_interface_creds
            - *quay_secret_push
            - *gitlab_token
            - *kas_fleet_manager_admin_staging
            - *kas_fleet_manager_admin_prod
    <<: *gl_build_master

- job-template:
    id: managed-kafka-client-workloads
    name: managed-kafka-client-workloads
    wrappers:
      - timestamps
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *quay_secret_pull
            - *ci_test_token
            - *ci_aws_keys
            - *ci_kas_abnormal_workloads
    concurrent: true
    parameters:
    - choice:
        name: CLIENT_APP
        description: 'Kafka client libraries to be used for scenarios execution'
        choices:
          - jvm
          - librdkafka-py
          - native-py
    - bool:
        name: PRODUCER
        default: 'true'
        description: 'Provision Producer Apps'
    - choice:
        name: PRODUCER_SCENARIO
        description: 'Abnormal producer workload scenario to be executed'
        choices:
          - bl
          - na
          - dc
          - nb
          - ps
    - bool:
        name: CONSUMER
        default: 'true'
        description: 'Provision Consumer Apps'
    - choice:
        name: CONSUMER_SCENARIO
        description: 'Abnormal consumer workload scenario to be executed'
        choices:
          - bl
          - ccg
          - gpc
          - mo
          - rp
    - string:
        name: CONSUMER_GROUPS
        default: '1'
        description: 'How many consumer groups to be used by consumer clients, clients are split equally between groups'
    - string:
        name: CLIENTS_PER_POD
        default: '5'
        description: 'Workload application concurent client instances'
    - string:
        name: RECORD_SIZE
        default: '100B'
        description: 'Size of each produced record in B/KB/MB'
    - string:
        name: MAX_THROUGHPUT
        default: '5KB'
        description: 'Max producer data output, consumer max data per fetch'
    - string:
        name: PODS
        default: '1'
        description: 'Number of pods running in parallel for each workload scenario (batch job parallelism)'
    - string:
        name: TEST_DURATION
        default: '30'
        description: 'Test duration in minutes, cluster lifespan will be extended if (now + TEST_DURATION + 60mins) > clusters expiration_timestamp'
    - string:
        name: TOPIC
        default: ''
        description: 'Specify an existing topic name if it should be reused'
    - string:
        name: BOOTSTRAP
        description: '[REQUIRED] Kafka Bootstrap Server'
    - choice:
        name: SASL_MODE
        description: 'Which SASL mode should be used'
        choices:
          - PLAIN
          - OAUTHBEARER
    - string:
        name: APP_IMAGE_TAG
        default: 'latest'
        description: 'Client application image tag to be used to provision workloads'
    - string:
        name: BRANCH
        default: '{default_branch}'
        description: 'The branch of kas-abnormal-workloads repo for pipeline scripts'
    branch: '${{BRANCH}}'
    <<: *gl_checkout
    builders:
    - shell: ./pipeline/deploy.sh
    artifacts_path: 'pipeline/results/logs/**,pipeline/results/delorean/cluster-details.json'
    publishers:
    - archive:
        artifacts: '{artifacts_path}'
        allow-empty: true

- job-template:
    id: mas-sso-perf-tests
    name: mas-sso-perf-tests-stage
    wrappers:
      - timeout_wrapper:
          timeout: "{timeout}"
      - ansicolor
      - vault-secrets:
          <<: *vault_defaults
          secrets:
            - *saas_mas_sso_perf_test_stage
    ci_cmd: './test/load-test/performanceTest.sh'
    <<: *gl_timed
